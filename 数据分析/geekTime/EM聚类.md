[TOC]

#EM聚类

EM:Expectation Maximization，最大期望算法。

算法过程分为两个步骤：

Expectation，期望步骤：初始化参数$\to$观察预期

Maximization，最大化步骤：重新估计参数$\to$ 初始化参数

##**EM算法工作原理**

EM的工作原理就是求解最大思然估计，通过观测样本，找出样本的模型参数。

最大似然：Maximum Likelihood ，通过已知结果，估计参数

通过旧参数来计算隐藏变量，然后通过得到的隐藏变量的结果重新估计参数，知道参数不再发生变化，得到想要的结果。参数的衡量标准是通过概率来计算，这点与K-Means不同。

##**EM聚类工作原理**

较 K-Means 算法，EM 聚类更加灵活

 K-Means 通过距离来区分样本，每个样本只能属于一个分类，称之为是**硬聚类算法**。

 EM 聚类通过概率求解样本，实际上每个样本都有一定的概率和每个聚类相关，叫做**软聚类算法**。

EM算法相当于一个框架，可以采用不同的模型来进行聚类，比如**GMM(高斯混合模型)**或**HMM（隐马尔科夫模型）**来进行聚类。很多K-Means解决不了的问题，EM聚类可以解决。

GMM是通过概率密度来进行聚类，聚成的类符合高斯分布，即正态分布。

HMM用到来马尔可夫过程，过程中通过状态转移矩阵来计算状态转移的概率。HMM在自然语言处理核语音识别领域中有广泛的应用。



