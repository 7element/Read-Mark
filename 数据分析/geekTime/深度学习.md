[TOC]

# 深度学习

深度学习属于机器学习的一种，目标同样是让机器具有智能，通过神经网络来实现。只需要告诉神经网络输入的数据是什么，输出是什么，深度学习会自己找到数据的特征规律。传统机器学习往往需要人工告诉机器采用什么样的模型算法，这是深度学习与传统机器学习最大的区别。

机器学习是人工智能一部分，指的是通过训练数据和算法模型让机器具有一定的智能。一般是通过已有的数据来学习知识，并通过各种算法模型形成一定的处理能力。当有新数据进来时，就可以通过训练好的模型对这些数据进行预测。

数据挖掘通常是从现有的数据中提取规律模式，以及使用算法模型。核心目的是找到这些数据变量之间的关系，因此会通过数据可视化对变量之间的关系进行呈现，用算法模型挖掘变量之间的关联关系。

## **神经网络工作原理**

**节点**：神经网络由神经元组成，称为节点，分布在神经网络的各个层中，这些层包括输入层、输出曾和隐藏层。

**输入层**：负责接收信号，并分发到隐藏层。一般将数据传给输入层。

**输出层**：负责输出结算结果，一般输出层节点数等于要分类的个数。

**隐藏层**：除了输入层和输出层外的神经网络都属于隐藏层，隐藏层可以是一层也可以是多层，每个隐藏层都会把前一层接点传输出来的数据进行计算。

**前向传播**：数据从输入层传递到输出曾的过程叫做前向传播。

**反向传播**：当前向传播作用到输出层得到分类结果之后，需要与实际值进行比对，从而得到误差。反向传播也叫作误差反向传播，核心原理是通过代价函数对网络中的参数进行修正，这样更容易让网络参数得到收敛。

**工作原理**：神经网络好比黑盒，只需要告诉这个黑盒子输入数据和输出数据，神经网络就可以自我训练。一旦训练好之后，可以像黑盒子一样使用，当传入一个新的数据时，会输出对应的输出结果。在训练过程中，神经网络主要是通过前向传播和反向传播机制运作。整个神经网络训练的过程就是不断的通过前向-反向传播迭代完成，当达到指定的迭代次数或者达到收敛标准的时候停止训练。然后拿训练好的网络模型对新的数据进行预测。

## **神经网络种类**

常用的神经网络结构，分别为**FNN**、**CNN**、**RNN**。

**FNN**：Fully-connected Neural Network，全连接神经网络。即每一层的神经元与上一层的所有神经元都是连接的。

**CNN**：卷积神经网络，广泛应用于图像处理，包括来卷积层、池化层和全连接层。

卷积层相当于一个滤镜作用，可以把图像进行分块，对每块图像进行变化操作。

池化层相当于神经元的数据进行降维处理，这样输出的维数就会减少很多，从而降低整体的计算量。

全连接层通常是输出曾的上一层，它将上一层神经元输出的数据转变成一维的向量。

**RNN**：循环神经网络，神经元的输出可以在下一个时刻作用到自身，RNN可以看做是在时间上传递的神经网络。可以应用在语音识别、自然语言处理等上下文相关的场景。

##**深度学习神经网络种类**

深度学习网络包括来FNN、CNN、RNN三种网络的变种形式，常用的神经网络包括：

AlexNet、VGG19、GoogleNet、ResNet等。

![](images/深度学习神经网络对比.png)

以上网络结构的提出与ILSVRC比赛相关，ILSVRC：Large Scale Visual Recognition Challenge。这是一个关于大规模图像可视化是别的比赛。Top-5正确率正是比赛的衡量指标之一。

## **深度学习应用领域**

深度学习有三大应用领域：

1.图像识别

2.语音识别

3.自然语言处理NLP